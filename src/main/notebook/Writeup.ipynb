{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Erasure coding for Pubsub: simulation results comparing Reed-Solomon and RLNC  \n",
    "\n",
    "## Abstract\n",
    "This simulation follows up on the writeup [Faster block/blob propagation in Ethereum](https://ethresear.ch/t/faster-block-blob-propagation-in-ethereum/21370) by @Potuz \n",
    "\n",
    "The goal is to compare potential pubsub protocol performance depending on the utilized erasure coding scheme: \n",
    "- Reed-Solomon (RS) erasure coding\n",
    "- RLNC erasure coding \n",
    "\n",
    "The major advantage of RLNC over RS with respect to pubsub is the ability to combine any chunks and get a new validatable chunk. \n",
    "Thus, if a node has, for example, two (or more) arbitrary chunks, with RS coding the node needs to choose which chunk it wants to propagate, while with RLNC coding the node would just propagate a random linear combination of existing 2 (or more) chunks. The latter could significantly reduce the chance of propagating duplicate information.        \n",
    "\n",
    "We also simulate an abstract pubsub protocol without any erasure coding which may be treated as a simplified version of the current Ethereum approach for blob dissemination.\n",
    "\n",
    "We also consider the [Ideal Pubsub](https://hackmd.io/@nashatyrev/rkXUsFD5a) model as a theoretical optimum for a pubsub protocol\n",
    "\n",
    "We consider very simple network model and very simple pubsub protocol implementations in which a _chunk_ is the only message nodes may send to each other. This simplicity should help in reasoning about why this or that statistical pattern is observed and also should help us to outline reasonable directions in developing a real protocol.           \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TLDR\n",
    "\n",
    "Utilizing erasure coding in a pubsub protocol may yield a significant dissemination performance gain for larger messages. \n",
    "\n",
    "In short: Reed-Solomon works great, but RLNC works greater. \n",
    "\n",
    "Below is the comparison of erasure coding types for different latencies. Please note that the time (both latency and result) is measured in abstract units defined below in [Simulation Model]() \n",
    "\n",
    "![compare chart](images/TldrCompareChart.png)\n",
    "\n",
    "More comparison details can be found [here](./Compare.ipynb).  \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation model\n",
    "\n",
    "- A message is split onto `numberOfChunks` _chunks_ of equal size\n",
    "- Every node has a _receive FIFO buffer_\n",
    "- Simulation is executed by _rounds_. \n",
    "- Each round every node may enqueue a single chunk to any other node receive buffer.\n",
    "    - The set of receiving nodes could be limited when simulating _meshes_ \n",
    "        - The meshes are randomly generated and are static across all rounds   \n",
    "- Each round every node pops and processes a single message from its receive buffer if it's not empty\n",
    "- The above rules simulate nodes' _bandwidth_ equal to 1 chunk/round\n",
    "- To abstract from the actual bandwidth and message size the _time_ is measured as a float value, \n",
    "    where `1.0` is the time the full message is transferred from one node to another with zero latency. \n",
    "    In other words the time `1.0` corresponds to the period of `numberOfChunks` rounds \n",
    "- The _latency_ is simulated in whole rounds (to keep the model simple). When the latency is non-zero the node \n",
    "    pops a message from receive buffer only if it was enqueued `latency` rounds ago\n",
    "- A node has no any information about the state (e.g. buffer size) of other nodes and no any global information besides the current round\n",
    "- The simulation completes when all the nodes receive the complete message. This is the only 'god' property of the model, when the global network state affects simulation        \n",
    "       "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation config\n",
    "\n",
    "- `nodeCount`: total number of nodes in the network\n",
    "- `numberOfChunks`: number of chunks the message is split onto\n",
    "- `peerCount` number of nodes in a mesh  \n",
    "- `erasure` the type of erasure coding and its applicable params: \n",
    "    - `NoErasure`: the message chunks are not erasure coded, they are disseminated 'as is' (is treated as a special case of `Rs` with extension factor `1.0`)\n",
    "        - `meshStrategy`: an attempt to make dynamic mesh size and reduce it in a later dissemination phase \n",
    "    - `RS`: Reed-Solomon erasure coding which has a predefined fixed number of extension chunks (in addition to `numberOfChunks` of original message chunks)\n",
    "        - `extensionFactor`: how many extension chunks are generated. Just `x2` and `x3` were tested\n",
    "                - `x1` corresponds to `NoErasure`\n",
    "        - `isDistinctMeshesPerChunk`: defines if distinct messages chunks are propagated via one or distinct meshes\n",
    "        - `chunkSelectionStrategy`: the strategy of how to select one from existing chunks to propagate at the current round  \n",
    "    - `RLNC`: RLNC erasure coding     \n",
    "- `latencyRounds`: the chunk delivery latency measured in rounds\n",
    "- `peerSelectionStrategy`: how the receiving peer is selected   "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation results\n",
    "\n",
    "The following key metrics are recorded every round: \n",
    "- `doneMsgCnt`: _non duplicate_ message count: the number of messages _received_ which are NOT duplicate for receiving nodes. \n",
    "    - when all nodes receive all necessary chunks and may recover original data the count reaches `numberOfChunks * (nodeCount - 1)`\n",
    "    - this metric is displayed with RED on stacked diagrams\n",
    "    - `doneMsgFraction`: relative `doneMsgCnt` value `[0.0 .. 1.0]`  \n",
    "- `dupMsgCnt`: _duplicate_ message count: the number of messages _received_ which don't add any information for receiving nodes and are dropped \n",
    "    - `dupBeforeReadyMsgCnt`: (subset of `dupMsgCnt`) is the number of duplicate messages received _before_ a node recovers original message  \n",
    "    - `dupAfterReadyMsgCnt`: (subset of `dupMsgCnt`) is the number of duplicate messages received _after_ a node recovers original message  "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Simulation\n",
    "\n",
    "Implementation and all the simulation Jupiter Notebooks could be found in this Github repo: https://github.com/Nashatyrev/potuz-pubsub\n",
    "\n",
    "Initially every erasure approach was simulated and tested, dissemination strategies were adjusted and nearly optimal parameters were selected for every strategy    \n",
    "- [NoErasure](./NoErasure.ipynb)\n",
    "- [Reed-Solomon](./RS.ipynb)\n",
    "- [RLNC](./RLNC.ipynb)\n",
    "\n",
    "Then compare under various angles of view: \n",
    "- [Compare](./Compare.ipynb)\n",
    " "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Both erasure approaches potentially empower pubsub protocol. However RLNC approach is potentially significantly more effective and tends toward theoretical pubsub optimum\n",
    "\n",
    "During simulation and results exploration a number of new questions had appeared. They are spread across notebooks and are subject for further investigations.         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
